# GPU Machine + FlashBlade Configuration
# Requires Nvidia GPUs and Pure Storage FlashBlade (pure-file StorageClass)
# Run: kubectl apply -f k8s_configs/gpu-flashblade.yaml

apiVersion: v1
kind: Namespace
metadata:
  name: fraud-pipeline
  labels:
    app.kubernetes.io/name: fraud-pipeline
---
# PVC using FlashBlade (pure-file)
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: fraud-pipeline-flashblade
  namespace: fraud-pipeline
  labels:
    app: "fraud-pipeline"
spec:
  storageClassName: pure-file
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
---
# Pod 1: CPU Generation (data-gather)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-gather
  namespace: fraud-pipeline
  labels:
    app: "data-gather"
    tier: "generation"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: "data-gather"
  template:
    metadata:
      labels:
        app: "data-gather"
        tier: "generation"
    spec:
      containers:
        - name: data-gather
          image: fraud-pipeline/data-gather:latest
          imagePullPolicy: Never
          env:
            - name: CONTINUOUS_MODE
              value: "true"
            - name: QUEUE_TYPE
              value: "flashblade"
            - name: FLASHBLADE_PATH
              value: "/mnt/flashblade"
            - name: PYTHONUNBUFFERED
              value: "1"
            - name: GENERATION_RATE
              value: "50000"
            - name: NUM_WORKERS
              value: "8"
            - name: CHUNK_SIZE
              value: "50000"
          volumeMounts:
            - name: flashblade
              mountPath: /mnt/flashblade
          resources:
            requests:
              cpu: "2000m"
              memory: "4Gi"
            limits:
              cpu: "8000m"
              memory: "16Gi"
      volumes:
        - name: flashblade
          persistentVolumeClaim:
            claimName: fraud-pipeline-flashblade
---
# Pod 3: GPU Preprocessing (RAPIDS)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: preprocessing-gpu
  namespace: fraud-pipeline
  labels:
    app: "preprocessing-gpu"
    tier: "preprocessing"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: "preprocessing-gpu"
  template:
    metadata:
      labels:
        app: "preprocessing-gpu"
        tier: "preprocessing"
    spec:
      containers:
        - name: preprocessing-gpu
          image: fraud-pipeline/preprocessing-gpu:latest
          imagePullPolicy: Never
          env:
            - name: CONTINUOUS_MODE
              value: "true"
            - name: QUEUE_TYPE
              value: "flashblade"
            - name: FLASHBLADE_PATH
              value: "/mnt/flashblade"
            - name: PYTHONUNBUFFERED
              value: "1"
          volumeMounts:
            - name: flashblade
              mountPath: /mnt/flashblade
          resources:
            requests:
              cpu: "1000m"
              memory: "8Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "4000m"
              memory: "32Gi"
              nvidia.com/gpu: "1"
      volumes:
        - name: flashblade
          persistentVolumeClaim:
            claimName: fraud-pipeline-flashblade
---
# Pod 4: GPU Model Training
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-build
  namespace: fraud-pipeline
  labels:
    app: "model-build"
    tier: "training"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: "model-build"
  template:
    metadata:
      labels:
        app: "model-build"
        tier: "training"
    spec:
      containers:
        - name: model-build
          image: fraud-pipeline/model-build:latest
          imagePullPolicy: Never
          env:
            - name: CONTINUOUS_MODE
              value: "true"
            - name: QUEUE_TYPE
              value: "flashblade"
            - name: FLASHBLADE_PATH
              value: "/mnt/flashblade"
            - name: PYTHONUNBUFFERED
              value: "1"
          volumeMounts:
            - name: flashblade
              mountPath: /mnt/flashblade
          resources:
            requests:
              cpu: "2000m"
              memory: "16Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "8000m"
              memory: "64Gi"
              nvidia.com/gpu: "1"
      volumes:
        - name: flashblade
          persistentVolumeClaim:
            claimName: fraud-pipeline-flashblade
---
# Pod 6: GPU Inference (Triton)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-gpu
  namespace: fraud-pipeline
  labels:
    app: "inference-gpu"
    tier: "inference"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: "inference-gpu"
  template:
    metadata:
      labels:
        app: "inference-gpu"
        tier: "inference"
    spec:
      containers:
        - name: inference-gpu
          image: fraud-pipeline/inference-gpu:latest
          imagePullPolicy: Never
          ports:
            - containerPort: 8000
              name: http
            - containerPort: 8001
              name: grpc
            - containerPort: 8002
              name: metrics
          env:
            - name: QUEUE_TYPE
              value: "flashblade"
            - name: FLASHBLADE_PATH
              value: "/mnt/flashblade"
            - name: PYTHONUNBUFFERED
              value: "1"
          volumeMounts:
            - name: flashblade
              mountPath: /mnt/flashblade
          resources:
            requests:
              cpu: "1000m"
              memory: "8Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "4000m"
              memory: "32Gi"
              nvidia.com/gpu: "1"
      volumes:
        - name: flashblade
          persistentVolumeClaim:
            claimName: fraud-pipeline-flashblade
---
# Service for inference-gpu
apiVersion: v1
kind: Service
metadata:
  name: inference-gpu
  namespace: fraud-pipeline
  labels:
    app: "inference-gpu"
spec:
  selector:
    app: "inference-gpu"
  ports:
    - name: http
      port: 8000
      targetPort: 8000
    - name: grpc
      port: 8001
      targetPort: 8001
    - name: metrics
      port: 8002
      targetPort: 8002
---
# ServiceAccount + RBAC for backend
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fraud-backend
  namespace: fraud-pipeline
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: fraud-backend-role
  namespace: fraud-pipeline
rules:
  - apiGroups: ["apps"]
    resources: ["deployments", "deployments/scale"]
    verbs: ["get", "list", "patch", "update"]
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: fraud-backend-binding
  namespace: fraud-pipeline
subjects:
  - kind: ServiceAccount
    name: fraud-backend
    namespace: fraud-pipeline
roleRef:
  kind: Role
  name: fraud-backend-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fraud-backend-nodes
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fraud-backend-nodes-binding
subjects:
  - kind: ServiceAccount
    name: fraud-backend
    namespace: fraud-pipeline
roleRef:
  kind: ClusterRole
  name: fraud-backend-nodes
  apiGroup: rbac.authorization.k8s.io
---
# Backend: Dashboard API
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: fraud-pipeline
  labels:
    app: "backend"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: "backend"
  template:
    metadata:
      labels:
        app: "backend"
    spec:
      serviceAccountName: fraud-backend
      containers:
        - name: backend
          image: fraud-pipeline/backend:latest
          imagePullPolicy: Never
          ports:
            - containerPort: 8000
              name: http
          env:
            - name: QUEUE_TYPE
              value: "flashblade"
            - name: CONFIG_MODE
              value: "gpu"
            - name: FLASHBLADE_PATH
              value: "/mnt/flashblade"
            - name: PROMETHEUS_URL
              value: ""
            - name: PURE_SERVER
              value: "true"
          volumeMounts:
            - name: flashblade
              mountPath: /mnt/flashblade
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "1000m"
              memory: "1Gi"
      volumes:
        - name: flashblade
          persistentVolumeClaim:
            claimName: fraud-pipeline-flashblade
---
apiVersion: v1
kind: Service
metadata:
  name: backend
  namespace: fraud-pipeline
  labels:
    app: "backend"
spec:
  selector:
    app: "backend"
  ports:
    - name: http
      port: 8000
      targetPort: 8000
